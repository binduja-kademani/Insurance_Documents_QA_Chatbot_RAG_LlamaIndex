{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%pip install llama_index transformers\n",
    "#%pip install python-dotenv\n",
    "#%pip install nest_asyncio\n",
    "# %pip install diskcache\n",
    "#%pip install llama-index-embeddings-huggingface\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio\n",
    "\n",
    "from llama_index.core import  VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "import chromadb\n",
    "\n",
    "import time\n",
    "\n",
    "from diskcache import Cache\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API Key\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\"./chroma.db\")\n",
    "cache = Cache(\"./cache\")\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"Please enter your OpenAI API Key\")\n",
    "api_key = getpass.getpass()\n",
    "openai.api_key = api_key\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "pdf_dir_path = \"./Dataset_folder\"\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ)\n",
    "#print(api_key)\n",
    "\n",
    "# docs = []\n",
    "# for doc in documnet:\n",
    "#     docs.append(doc.text)\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(pdf_dir_path, storage_context):\n",
    "    docs = SimpleDirectoryReader(pdf_dir_path).load_data()\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            SentenceSplitter(),\n",
    "            TitleExtractor(),\n",
    "            #HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "            OpenAIEmbedding(model_name=\"text-embedding-ada-002\"),\n",
    "        ]\n",
    "    )\n",
    "    nodes = pipeline.run(documents=docs)\n",
    "    index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index():\n",
    "    print(\"Creating and saving the index\")\n",
    "    try:\n",
    "        chroma_collection = chroma_client.create_collection(name=\"Insurance_Doc_RAG_LlamaIndex\")\n",
    "    except Exception as e:\n",
    "        print(f\"Collection already exists: {e}\")\n",
    "        chroma_collection = chroma_client.get_collection(name=\"Insurance_Doc_RAG_LlamaIndex\")\n",
    "\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    try:\n",
    "        index = build_index(pdf_dir_path, storage_context)\n",
    "        print(\"Index created and saved\")\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(f\"Error while building the index: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index():\n",
    "    try:\n",
    "        chroma_collection = chroma_client.get_collection(name=\"Insurance_Doc_RAG_LlamaIndex\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the collection: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Loading the index\")\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    try:\n",
    "        index = VectorStoreIndex.from_vector_store(\n",
    "            vector_store=vector_store,\n",
    "            storage_context=storage_context\n",
    "        )\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading the index: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector_Index = VectorStoreIndex()\n",
    "# index = Vector_Index.build_index_from_nodes(nodes=nodes)\n",
    "# Load documents\n",
    "# pdf_dir_path = r\"C:\\Users\\sandy\\Downloads\\Policy+Documents\"\n",
    "# docs = SimpleDirectoryReader(pdf_dir_path).load_data()\n",
    "\n",
    "# with open('vector_store_index.pkl', 'rb') as f:\n",
    "#     loaded_index = pickle.load(f)\n",
    "\n",
    "# if loaded_index is not None:\n",
    "#     index = loaded_index\n",
    "# else:\n",
    "#     index = build_index(pdf_dir_path)\n",
    "#     with open(\"vector_store_index.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = index.as_retriever()\n",
    "\n",
    "# results = retriever.retrieve(\"What is the procedure to claim the insurance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for res in results:\n",
    "#     print(res.node.metadata[\"document_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# %pip install tf_keras\n",
    "#%pip uninstall keras\n",
    "#%pip install keras==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_comm(query, index):\n",
    "    retriever = index.as_retriever()\n",
    "    results = retriever.retrieve(query)\n",
    "\n",
    "    system_message = f\"\"\"You are an Question answering expert. The user will ask you a question/query. \n",
    "    The Question is : {query}\n",
    "    Now, the Documents related to the question is : {[res.node.text for res in results]}\n",
    "    If the question is related to the document, answer it using the information in the document.\n",
    "    If the question is not related to the document, answer \"Please contact the insurance company/agent as I am not able to answer the question\".\n",
    "    If you answer the question, please provide the relevant document as reference.\n",
    "    Reference Format : Page Number | Document Name.\n",
    "    Page Numbers is {[res.node.metadata['page_label'] for res in results]}\n",
    "    Document Names is {[res.node.metadata['document_title'] for res in results]}\n",
    "    Example:\n",
    "    Reference 1 : Page 4 | Accidental Death Benefit Claims Procedure and Exclusions\n",
    "    etc.\n",
    "    Use all the info retrieved and if used then give the reference. Multiple references can be used.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-4o-mini\", system_prompt=system_message)\n",
    "\n",
    "    query_engine = index.as_query_engine(response_mode=\"compact\", similirty_top_k=3, llm=llm, node_postprocessors=[rerank])\n",
    "    response = query_engine.query(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the index\n",
      "Index is ready\n",
      "Welcome to Insurance Documentation Chatbot. Please enter your query.\n",
      "User:  What is the procedure to claim the insurance?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Searching in Cache... Please wait!\n",
      "Data found in Cache. Retrieving relevant information...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "To claim the insurance, the following procedure should be followed:\n",
      "\n",
      "1. Ensure that the claim is valid and meets the definitions and exclusion criteria outlined in the policy.\n",
      "2. If the claim is for Open Heart Replacement or Repair of Heart Valves, it must be determined to be medically necessary by a Consultant Cardiologist or Surgeon, supported by relevant imaging findings and established diagnostic reports.\n",
      "3. The benefit as set out in the Scheme Memberâ€™s Certificate of Insurance will be paid to the Nominee of the deceased Scheme Member for Single Life cases, and for Joint Life cases, to the surviving life. If the benefit is in the form of an acceleration of the death benefit and the Scheme Member is alive, then the benefit shall be payable to the Scheme Member.\n",
      "4. The Insurer is responsible for honoring valid claims even if the Master Policyholder has collected the premium but failed to pay it to the Insurer within the grace period due to administrative reasons.\n",
      "5. In case of a claim involving a loan balance, specific authorizations and documentation must be provided to the Insurer, including a Credit Account Statement and written authorization from the Scheme Member.\n",
      "\n",
      "For further details, please refer to the following documents:\n",
      "- Page 8 | Comprehensive Guide to Insurance Policy Benefits and Claims Procedures\n",
      "- Page 10 | Comprehensive Guide to Insurance Coverage Options, Policy Management, and Terms of Claims, Revival, and Termination\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Thanks for using Insurance Documentation Chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "index = load_index()\n",
    "if index is None:\n",
    "    index = save_index()\n",
    "\n",
    "if index:\n",
    "    print(\"Index is ready\")\n",
    "else:\n",
    "    print(\"Failed to create or load the index\")\n",
    "\n",
    "\n",
    "print(\"Welcome to Insurance Documentation Chatbot. Please enter your query.\")\n",
    "query = input()\n",
    "print(\"User: \", query)\n",
    "print(\"-\"*100)\n",
    "time.sleep(1)\n",
    "print(\"Searching in Cache... Please wait!\")\n",
    "if cache.get(query) is not None:\n",
    "    print(\"Data found in Cache. Retrieving relevant information...\")\n",
    "    time.sleep(1)\n",
    "    response = cache.get(query)\n",
    "else:\n",
    "    print(\"Data not found in Cache. Searching in Documents...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Data Found. Retrieving relevant information...\")\n",
    "    response = query_comm(query, index)\n",
    "    cache.set(query, response, expire=600)\n",
    "print(\"-\"*100)\n",
    "print(response)\n",
    "print(\"-\"*100)\n",
    "print(\"Thanks for using Insurance Documentation Chatbot. Have a great day!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
